{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytic Geometry (Lecture 3)\n",
    "\n",
    "**Course:** Mathematics for Machine Learning  \n",
    "**Instructor:** Mohammed Alnemari\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Compute **norms** (L1, L2, L-infinity) and visualize unit balls\n",
    "2. Work with **inner products** and verify positive definiteness\n",
    "3. Calculate **distances** and **angles** between vectors\n",
    "4. Check **orthogonality** and build orthogonal complements\n",
    "5. Perform **projections** onto lines and subspaces\n",
    "6. Implement the **Gram-Schmidt** orthogonalization process\n",
    "7. Construct and apply **rotation** matrices\n",
    "\n",
    "---\n",
    "\n",
    "## Google Colab Ready!\n",
    "\n",
    "This notebook works perfectly in Google Colab. All required libraries are pre-installed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "\n",
    "# For nicer plots\n",
    "plt.rcParams['figure.figsize'] = (6, 5)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Norms\n",
    "\n",
    "A **norm** assigns a non-negative length or size to each vector in a vector space.\n",
    "\n",
    "Common norms for a vector $\\mathbf{x} = (x_1, x_2, \\ldots, x_n)$:\n",
    "\n",
    "- **L1 norm (Manhattan):** $\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^{n} |x_i|$\n",
    "- **L2 norm (Euclidean):** $\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^{n} x_i^2}$\n",
    "- **L-infinity norm (Max):** $\\|\\mathbf{x}\\|_\\infty = \\max_i |x_i|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Computing Norms with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a vector\n",
    "x = np.array([3, -4, 1, 2])\n",
    "print(\"Vector x =\", x)\n",
    "print()\n",
    "\n",
    "# L1 norm (Manhattan norm)\n",
    "l1_norm = np.linalg.norm(x, ord=1)\n",
    "print(\"L1 norm  ||x||_1   =\", l1_norm)\n",
    "\n",
    "# L2 norm (Euclidean norm)\n",
    "l2_norm = np.linalg.norm(x, ord=2)\n",
    "print(\"L2 norm  ||x||_2   =\", l2_norm)\n",
    "\n",
    "# L-infinity norm (Max norm)\n",
    "linf_norm = np.linalg.norm(x, ord=np.inf)\n",
    "print(\"Linf norm ||x||_inf =\", linf_norm)\n",
    "print()\n",
    "\n",
    "# Verify by hand\n",
    "print(\"Manual L1:  \", np.sum(np.abs(x)))\n",
    "print(\"Manual L2:  \", np.sqrt(np.sum(x**2)))\n",
    "print(\"Manual Linf:\", np.max(np.abs(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Visualizing Unit Balls in 2D\n",
    "\n",
    "The **unit ball** for a norm is the set of all points with norm $\\leq 1$:\n",
    "$\\{ \\mathbf{x} : \\|\\mathbf{x}\\| \\leq 1 \\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a grid of points in 2D\n",
    "grid = np.linspace(-1.5, 1.5, 500)\n",
    "X, Y = np.meshgrid(grid, grid)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# L1 unit ball: |x| + |y| <= 1 (diamond)\n",
    "Z1 = np.abs(X) + np.abs(Y)\n",
    "axes[0].contourf(X, Y, Z1, levels=[0, 1], colors=['#3498db'], alpha=0.5)\n",
    "axes[0].contour(X, Y, Z1, levels=[1], colors=['#2c3e50'], linewidths=2)\n",
    "axes[0].set_title('L1 Unit Ball (Diamond)', fontsize=13)\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axhline(0, color='k', linewidth=0.5)\n",
    "axes[0].axvline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# L2 unit ball: sqrt(x^2 + y^2) <= 1 (circle)\n",
    "Z2 = np.sqrt(X**2 + Y**2)\n",
    "axes[1].contourf(X, Y, Z2, levels=[0, 1], colors=['#2ecc71'], alpha=0.5)\n",
    "axes[1].contour(X, Y, Z2, levels=[1], colors=['#2c3e50'], linewidths=2)\n",
    "axes[1].set_title('L2 Unit Ball (Circle)', fontsize=13)\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].axhline(0, color='k', linewidth=0.5)\n",
    "axes[1].axvline(0, color='k', linewidth=0.5)\n",
    "\n",
    "# L-infinity unit ball: max(|x|, |y|) <= 1 (square)\n",
    "Zinf = np.maximum(np.abs(X), np.abs(Y))\n",
    "axes[2].contourf(X, Y, Zinf, levels=[0, 1], colors=['#e74c3c'], alpha=0.5)\n",
    "axes[2].contour(X, Y, Zinf, levels=[1], colors=['#2c3e50'], linewidths=2)\n",
    "axes[2].set_title('L-inf Unit Ball (Square)', fontsize=13)\n",
    "axes[2].set_aspect('equal')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "axes[2].axhline(0, color='k', linewidth=0.5)\n",
    "axes[2].axvline(0, color='k', linewidth=0.5)\n",
    "\n",
    "plt.suptitle('Unit Balls for Different Norms', fontsize=15, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Inner Products\n",
    "\n",
    "An **inner product** $\\langle \\mathbf{x}, \\mathbf{y} \\rangle$ is a generalization of the dot product.\n",
    "\n",
    "- **Standard dot product:** $\\langle \\mathbf{x}, \\mathbf{y} \\rangle = \\mathbf{x}^\\top \\mathbf{y} = \\sum_i x_i y_i$\n",
    "- **Generalized inner product:** $\\langle \\mathbf{x}, \\mathbf{y} \\rangle_A = \\mathbf{x}^\\top A \\mathbf{y}$ where $A$ is symmetric positive definite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Dot Product with np.dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two vectors\n",
    "x = np.array([1, 2, 3])\n",
    "y = np.array([4, 5, 6])\n",
    "\n",
    "# Compute dot product (three equivalent ways)\n",
    "dot1 = np.dot(x, y)\n",
    "dot2 = x @ y\n",
    "dot3 = np.sum(x * y)\n",
    "\n",
    "print(\"x =\", x)\n",
    "print(\"y =\", y)\n",
    "print()\n",
    "print(\"np.dot(x, y) =\", dot1)\n",
    "print(\"x @ y        =\", dot2)\n",
    "print(\"sum(x * y)   =\", dot3)\n",
    "print()\n",
    "print(\"All methods agree:\", dot1 == dot2 == dot3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Custom Inner Product with Matrix A\n",
    "\n",
    "Given a symmetric positive definite matrix $A$, we can define an inner product:\n",
    "\n",
    "$$\\langle \\mathbf{x}, \\mathbf{y} \\rangle_A = \\mathbf{x}^\\top A \\, \\mathbf{y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a symmetric positive definite matrix A\n",
    "A = np.array([[2, 1],\n",
    "              [1, 3]])\n",
    "\n",
    "# Define two 2D vectors\n",
    "x = np.array([1, 0])\n",
    "y = np.array([0, 1])\n",
    "\n",
    "# Standard dot product\n",
    "std_dot = np.dot(x, y)\n",
    "print(\"Standard dot product: <x, y> =\", std_dot)\n",
    "\n",
    "# Custom inner product: x^T A y\n",
    "custom_ip = x @ A @ y\n",
    "print(\"Custom inner product: <x, y>_A =\", custom_ip)\n",
    "print()\n",
    "\n",
    "# The custom inner product can detect 'similarity' that\n",
    "# the standard dot product misses\n",
    "print(\"Note: Standard dot product says x and y are orthogonal.\")\n",
    "print(\"The A-inner product shows they are NOT A-orthogonal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Checking Positive Definiteness\n",
    "\n",
    "A symmetric matrix $A$ is **positive definite** if all its eigenvalues are positive.\n",
    "This is required for $A$ to define a valid inner product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a matrix is positive definite\n",
    "def is_positive_definite(M):\n",
    "    \"\"\"Check if matrix M is symmetric positive definite.\"\"\"\n",
    "    # Check symmetry\n",
    "    if not np.allclose(M, M.T):\n",
    "        return False, \"Not symmetric\"\n",
    "    # Check eigenvalues\n",
    "    eigenvalues = np.linalg.eigvalsh(M)\n",
    "    if np.all(eigenvalues > 0):\n",
    "        return True, eigenvalues\n",
    "    else:\n",
    "        return False, eigenvalues\n",
    "\n",
    "# Test with a positive definite matrix\n",
    "A = np.array([[2, 1],\n",
    "              [1, 3]])\n",
    "result, info = is_positive_definite(A)\n",
    "print(\"Matrix A:\")\n",
    "print(A)\n",
    "print(\"Positive definite?\", result)\n",
    "print(\"Eigenvalues:\", info)\n",
    "print()\n",
    "\n",
    "# Test with a non-positive-definite matrix\n",
    "B = np.array([[1, 2],\n",
    "              [2, 1]])\n",
    "result, info = is_positive_definite(B)\n",
    "print(\"Matrix B:\")\n",
    "print(B)\n",
    "print(\"Positive definite?\", result)\n",
    "print(\"Eigenvalues:\", info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Distances and Angles\n",
    "\n",
    "Using inner products and norms, we can compute distances and angles between vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two points\n",
    "p = np.array([1, 2, 3])\n",
    "q = np.array([4, 6, 3])\n",
    "\n",
    "# Euclidean distance = ||p - q||_2\n",
    "dist = np.linalg.norm(p - q)\n",
    "print(\"Point p =\", p)\n",
    "print(\"Point q =\", q)\n",
    "print()\n",
    "print(\"Euclidean distance d(p, q) =\", dist)\n",
    "print(\"Manual calculation:\", np.sqrt(np.sum((p - q)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Cosine Similarity and Angle Between Vectors\n",
    "\n",
    "The angle $\\theta$ between two vectors is given by:\n",
    "\n",
    "$$\\cos \\theta = \\frac{\\langle \\mathbf{x}, \\mathbf{y} \\rangle}{\\|\\mathbf{x}\\| \\cdot \\|\\mathbf{y}\\|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two vectors\n",
    "x = np.array([1, 0])\n",
    "y = np.array([1, 1])\n",
    "\n",
    "# Cosine similarity\n",
    "cos_sim = np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "print(\"x =\", x)\n",
    "print(\"y =\", y)\n",
    "print()\n",
    "print(\"Cosine similarity:\", cos_sim)\n",
    "\n",
    "# Angle in radians and degrees\n",
    "angle_rad = np.arccos(np.clip(cos_sim, -1, 1))\n",
    "angle_deg = np.degrees(angle_rad)\n",
    "print(\"Angle (radians):\", angle_rad)\n",
    "print(\"Angle (degrees):\", angle_deg)\n",
    "print()\n",
    "\n",
    "# Another example\n",
    "a = np.array([1, 0])\n",
    "b = np.array([0, 1])\n",
    "cos_ab = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "angle_ab = np.degrees(np.arccos(np.clip(cos_ab, -1, 1)))\n",
    "print(\"Angle between [1,0] and [0,1]:\", angle_ab, \"degrees (perpendicular)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Verify the Cauchy-Schwarz Inequality\n",
    "\n",
    "$$|\\langle \\mathbf{x}, \\mathbf{y} \\rangle| \\leq \\|\\mathbf{x}\\| \\cdot \\|\\mathbf{y}\\|$$\n",
    "\n",
    "Equality holds if and only if $\\mathbf{x}$ and $\\mathbf{y}$ are linearly dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Cauchy-Schwarz with random vectors\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Cauchy-Schwarz Inequality: |<x,y>| <= ||x|| * ||y||\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "for i in range(5):\n",
    "    x = np.random.randn(4)\n",
    "    y = np.random.randn(4)\n",
    "    \n",
    "    lhs = np.abs(np.dot(x, y))           # |<x, y>|\n",
    "    rhs = np.linalg.norm(x) * np.linalg.norm(y)  # ||x|| * ||y||\n",
    "    \n",
    "    print(f\"Trial {i+1}: |<x,y>| = {lhs:.4f}  <=  ||x||*||y|| = {rhs:.4f}  \"\n",
    "          f\"  Holds: {lhs <= rhs + 1e-10}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Equality case: x and y are linearly dependent\n",
    "x = np.array([1, 2, 3])\n",
    "y = 5 * x  # y is a scalar multiple of x\n",
    "lhs = np.abs(np.dot(x, y))\n",
    "rhs = np.linalg.norm(x) * np.linalg.norm(y)\n",
    "print(\"Equality case (y = 5x):\")\n",
    "print(f\"  |<x,y>| = {lhs:.4f}  ==  ||x||*||y|| = {rhs:.4f}\")\n",
    "print(f\"  Equal? {np.isclose(lhs, rhs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Orthogonality\n",
    "\n",
    "Two vectors $\\mathbf{x}$ and $\\mathbf{y}$ are **orthogonal** if $\\langle \\mathbf{x}, \\mathbf{y} \\rangle = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Checking Orthogonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vectors\n",
    "u = np.array([1, 0, 0])\n",
    "v = np.array([0, 1, 0])\n",
    "w = np.array([1, 1, 0])\n",
    "\n",
    "def check_orthogonal(a, b, name_a=\"a\", name_b=\"b\"):\n",
    "    \"\"\"Check if two vectors are orthogonal.\"\"\"\n",
    "    dot = np.dot(a, b)\n",
    "    is_orth = np.isclose(dot, 0)\n",
    "    print(f\"<{name_a}, {name_b}> = {dot:.4f}  ->  Orthogonal? {is_orth}\")\n",
    "    return is_orth\n",
    "\n",
    "print(\"u =\", u)\n",
    "print(\"v =\", v)\n",
    "print(\"w =\", w)\n",
    "print()\n",
    "\n",
    "check_orthogonal(u, v, \"u\", \"v\")\n",
    "check_orthogonal(u, w, \"u\", \"w\")\n",
    "check_orthogonal(v, w, \"v\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Orthogonal Complement\n",
    "\n",
    "The **orthogonal complement** of a subspace $U$ is the set of all vectors orthogonal to every vector in $U$.\n",
    "\n",
    "We can find it using the null space of the matrix whose rows span $U$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a subspace spanned by two vectors in R^3\n",
    "u1 = np.array([1, 0, 1])\n",
    "u2 = np.array([0, 1, 1])\n",
    "\n",
    "# Stack them as rows of a matrix\n",
    "U = np.vstack([u1, u2])\n",
    "print(\"Subspace basis (as rows):\")\n",
    "print(U)\n",
    "print()\n",
    "\n",
    "# Find orthogonal complement using SVD (null space of U)\n",
    "# The null space is spanned by right singular vectors\n",
    "# corresponding to zero singular values\n",
    "_, S, Vt = np.linalg.svd(U)\n",
    "print(\"Singular values:\", S)\n",
    "\n",
    "# Vectors in Vt beyond the rank form the null space\n",
    "rank = np.sum(S > 1e-10)\n",
    "null_space = Vt[rank:]  # orthogonal complement basis\n",
    "\n",
    "print(\"Rank of U:\", rank)\n",
    "print()\n",
    "print(\"Orthogonal complement basis:\")\n",
    "print(null_space)\n",
    "print()\n",
    "\n",
    "# Verify orthogonality\n",
    "for i, nc in enumerate(null_space):\n",
    "    print(f\"<u1, null_vec_{i+1}> = {np.dot(u1, nc):.6f}\")\n",
    "    print(f\"<u2, null_vec_{i+1}> = {np.dot(u2, nc):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Orthogonal Matrix Verification\n",
    "\n",
    "A square matrix $Q$ is **orthogonal** if $Q^\\top Q = Q Q^\\top = I$.\n",
    "\n",
    "Equivalently, its columns (and rows) form an orthonormal set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct an orthogonal matrix using a rotation\n",
    "theta = np.pi / 4  # 45 degrees\n",
    "Q = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "              [np.sin(theta),  np.cos(theta)]])\n",
    "\n",
    "print(\"Orthogonal matrix Q (45-degree rotation):\")\n",
    "print(Q)\n",
    "print()\n",
    "\n",
    "# Verify Q^T Q = I\n",
    "QtQ = Q.T @ Q\n",
    "print(\"Q^T @ Q:\")\n",
    "print(QtQ)\n",
    "print()\n",
    "\n",
    "# Check if close to identity\n",
    "I = np.eye(2)\n",
    "print(\"Q^T Q == I?\", np.allclose(QtQ, I))\n",
    "print()\n",
    "\n",
    "# Verify determinant is +1 or -1\n",
    "det_Q = np.linalg.det(Q)\n",
    "print(\"det(Q) =\", det_Q)\n",
    "print(\"det(Q) = +/-1?\", np.isclose(np.abs(det_Q), 1))\n",
    "print()\n",
    "\n",
    "# Column norms should all be 1\n",
    "for j in range(Q.shape[1]):\n",
    "    print(f\"||column {j+1}|| = {np.linalg.norm(Q[:, j]):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Projections\n",
    "\n",
    "**Projection** maps a vector onto a subspace, finding the closest point in that subspace.\n",
    "\n",
    "- Projection onto a line (1D subspace spanned by $\\mathbf{b}$): $\\text{proj}_{\\mathbf{b}}(\\mathbf{x}) = \\frac{\\mathbf{b}^\\top \\mathbf{x}}{\\mathbf{b}^\\top \\mathbf{b}} \\mathbf{b}$\n",
    "\n",
    "- Projection onto a general subspace (columns of $B$): $\\text{proj}_B(\\mathbf{x}) = B(B^\\top B)^{-1} B^\\top \\mathbf{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Projection onto a Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection of x onto the line spanned by b\n",
    "x = np.array([3, 4])\n",
    "b = np.array([1, 1])\n",
    "\n",
    "# proj_b(x) = (b^T x / b^T b) * b\n",
    "scalar = np.dot(b, x) / np.dot(b, b)\n",
    "proj = scalar * b\n",
    "\n",
    "print(\"Vector x =\", x)\n",
    "print(\"Line direction b =\", b)\n",
    "print()\n",
    "print(\"Projection coefficient (lambda):\", scalar)\n",
    "print(\"Projection proj_b(x) =\", proj)\n",
    "print()\n",
    "\n",
    "# The residual should be orthogonal to b\n",
    "residual = x - proj\n",
    "print(\"Residual (x - proj):\", residual)\n",
    "print(\"<residual, b> =\", np.dot(residual, b), \"(should be 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Projection onto a General Subspace\n",
    "\n",
    "$$\\pi_B(\\mathbf{x}) = B(B^\\top B)^{-1} B^\\top \\mathbf{x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subspace basis (columns of B) in R^3\n",
    "B = np.array([[1, 0],\n",
    "              [0, 1],\n",
    "              [0, 0]])  # xy-plane in R^3\n",
    "\n",
    "# Vector to project\n",
    "x = np.array([2, 3, 5])\n",
    "\n",
    "# Projection matrix: P = B (B^T B)^{-1} B^T\n",
    "P = B @ np.linalg.inv(B.T @ B) @ B.T\n",
    "print(\"Projection matrix P:\")\n",
    "print(P)\n",
    "print()\n",
    "\n",
    "# Compute projection\n",
    "proj = P @ x\n",
    "print(\"Vector x =\", x)\n",
    "print(\"Projection onto xy-plane:\", proj)\n",
    "print()\n",
    "\n",
    "# Verify: P is idempotent (P^2 = P)\n",
    "print(\"P^2 == P?\", np.allclose(P @ P, P))\n",
    "\n",
    "# Verify: P is symmetric\n",
    "print(\"P == P^T?\", np.allclose(P, P.T))\n",
    "print()\n",
    "\n",
    "# Residual should be orthogonal to the subspace\n",
    "residual = x - proj\n",
    "print(\"Residual:\", residual)\n",
    "print(\"B^T @ residual =\", B.T @ residual, \"(should be zero vector)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Visualize Projection in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize projection of x onto line through b\n",
    "x = np.array([3, 4])\n",
    "b = np.array([2, 1])\n",
    "\n",
    "# Compute projection\n",
    "proj = (np.dot(b, x) / np.dot(b, b)) * b\n",
    "residual = x - proj\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n",
    "\n",
    "# Draw the line through b (extended)\n",
    "t = np.linspace(-1, 3, 100)\n",
    "line_x = t * b[0]\n",
    "line_y = t * b[1]\n",
    "ax.plot(line_x, line_y, 'k--', alpha=0.3, label='Subspace (line)')\n",
    "\n",
    "# Draw vectors\n",
    "ax.annotate('', xy=x, xytext=(0, 0),\n",
    "            arrowprops=dict(arrowstyle='->', color='blue', lw=2))\n",
    "ax.annotate('', xy=proj, xytext=(0, 0),\n",
    "            arrowprops=dict(arrowstyle='->', color='green', lw=2))\n",
    "ax.annotate('', xy=x, xytext=proj,\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=2, linestyle='dashed'))\n",
    "\n",
    "# Labels\n",
    "ax.text(x[0] + 0.1, x[1] + 0.1, '$\\mathbf{x}$', fontsize=14, color='blue')\n",
    "ax.text(proj[0] - 0.3, proj[1] - 0.4, '$\\mathrm{proj}(\\mathbf{x})$',\n",
    "        fontsize=12, color='green')\n",
    "ax.text((x[0] + proj[0]) / 2 + 0.15, (x[1] + proj[1]) / 2,\n",
    "        'residual', fontsize=11, color='red')\n",
    "\n",
    "# Draw right-angle marker\n",
    "corner_size = 0.2\n",
    "r_unit = residual / np.linalg.norm(residual)\n",
    "b_unit = b / np.linalg.norm(b)\n",
    "corner = np.array([proj + corner_size * r_unit,\n",
    "                   proj + corner_size * r_unit + corner_size * b_unit,\n",
    "                   proj + corner_size * b_unit])\n",
    "ax.plot(corner[:, 0], corner[:, 1], 'k-', lw=1)\n",
    "\n",
    "ax.set_xlim(-0.5, 5)\n",
    "ax.set_ylim(-0.5, 5)\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(0, color='k', linewidth=0.5)\n",
    "ax.axvline(0, color='k', linewidth=0.5)\n",
    "ax.set_title('Projection of x onto a Line', fontsize=14)\n",
    "ax.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: Gram-Schmidt Orthogonalization\n",
    "\n",
    "The **Gram-Schmidt process** takes a set of linearly independent vectors and produces an orthonormal set.\n",
    "\n",
    "Given vectors $\\{\\mathbf{b}_1, \\ldots, \\mathbf{b}_n\\}$, Gram-Schmidt produces $\\{\\mathbf{q}_1, \\ldots, \\mathbf{q}_n\\}$ such that:\n",
    "- $\\langle \\mathbf{q}_i, \\mathbf{q}_j \\rangle = 0$ for $i \\neq j$\n",
    "- $\\|\\mathbf{q}_i\\| = 1$ for all $i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Gram-Schmidt from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_schmidt(V):\n",
    "    \"\"\"\n",
    "    Perform Gram-Schmidt orthogonalization.\n",
    "    \n",
    "    Parameters:\n",
    "        V : array of shape (n, k) where columns are input vectors\n",
    "    \n",
    "    Returns:\n",
    "        Q : array of shape (n, k) with orthonormal columns\n",
    "    \"\"\"\n",
    "    n, k = V.shape\n",
    "    Q = np.zeros((n, k))\n",
    "    \n",
    "    for j in range(k):\n",
    "        # Start with the original vector\n",
    "        v = V[:, j].copy()\n",
    "        \n",
    "        # Subtract projections onto all previous orthonormal vectors\n",
    "        for i in range(j):\n",
    "            v = v - np.dot(Q[:, i], V[:, j]) * Q[:, i]\n",
    "        \n",
    "        # Normalize\n",
    "        norm_v = np.linalg.norm(v)\n",
    "        if norm_v < 1e-10:\n",
    "            raise ValueError(f\"Vector {j+1} is linearly dependent on previous vectors.\")\n",
    "        Q[:, j] = v / norm_v\n",
    "    \n",
    "    return Q\n",
    "\n",
    "\n",
    "# Test with 3 vectors in R^3\n",
    "V = np.array([[1, 1, 0],\n",
    "              [1, 0, 1],\n",
    "              [0, 1, 1]], dtype=float)\n",
    "\n",
    "print(\"Original vectors (columns of V):\")\n",
    "print(V)\n",
    "print()\n",
    "\n",
    "Q = gram_schmidt(V)\n",
    "print(\"Orthonormal vectors (columns of Q):\")\n",
    "print(Q)\n",
    "print()\n",
    "\n",
    "# Verify orthonormality: Q^T Q should be identity\n",
    "print(\"Q^T @ Q (should be identity):\")\n",
    "print(np.round(Q.T @ Q, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Compare with scipy.linalg.qr\n",
    "\n",
    "The QR decomposition factors a matrix $A = QR$ where $Q$ is orthogonal and $R$ is upper triangular.\n",
    "The columns of $Q$ are the result of Gram-Schmidt applied to the columns of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QR decomposition using SciPy\n",
    "Q_scipy, R_scipy = linalg.qr(V, mode='economic')\n",
    "\n",
    "print(\"SciPy Q (may differ in sign):\")\n",
    "print(Q_scipy)\n",
    "print()\n",
    "print(\"Our Gram-Schmidt Q:\")\n",
    "print(Q)\n",
    "print()\n",
    "\n",
    "# The columns may differ by a sign, but the subspaces are the same\n",
    "# Check by verifying Q^T Q_scipy has entries +1 or -1 on diagonal\n",
    "print(\"Absolute column dot products (should be 1.0):\")\n",
    "for j in range(Q.shape[1]):\n",
    "    dot = np.abs(np.dot(Q[:, j], Q_scipy[:, j]))\n",
    "    print(f\"  |<q_{j+1}, q_scipy_{j+1}>| = {dot:.6f}\")\n",
    "\n",
    "print()\n",
    "print(\"R matrix from QR decomposition:\")\n",
    "print(np.round(R_scipy, 6))\n",
    "\n",
    "print()\n",
    "print(\"Verify: Q @ R == V?\")\n",
    "print(np.allclose(Q_scipy @ R_scipy, V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 7: Rotations\n",
    "\n",
    "A **rotation matrix** in 2D rotates vectors by an angle $\\theta$ counterclockwise:\n",
    "\n",
    "$$R(\\theta) = \\begin{pmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{pmatrix}$$\n",
    "\n",
    "Properties:\n",
    "- $R$ is orthogonal: $R^\\top R = I$\n",
    "- $\\det(R) = 1$ (proper rotation)\n",
    "- Rotations preserve lengths and angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 2D Rotation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrix_2d(theta):\n",
    "    \"\"\"Create a 2D rotation matrix for angle theta (in radians).\"\"\"\n",
    "    c, s = np.cos(theta), np.sin(theta)\n",
    "    return np.array([[c, -s],\n",
    "                     [s,  c]])\n",
    "\n",
    "# Rotate a vector by 90 degrees\n",
    "theta = np.pi / 2  # 90 degrees\n",
    "R = rotation_matrix_2d(theta)\n",
    "\n",
    "v = np.array([1, 0])\n",
    "v_rotated = R @ v\n",
    "\n",
    "print(f\"Rotation angle: {np.degrees(theta)} degrees\")\n",
    "print(\"R =\")\n",
    "print(np.round(R, 6))\n",
    "print()\n",
    "print(\"Original vector:  \", v)\n",
    "print(\"Rotated vector:   \", np.round(v_rotated, 6))\n",
    "print()\n",
    "\n",
    "# Verify properties\n",
    "print(\"det(R) =\", np.round(np.linalg.det(R), 6))\n",
    "print(\"R^T R = I?\", np.allclose(R.T @ R, np.eye(2)))\n",
    "print(\"||v|| =\", np.linalg.norm(v))\n",
    "print(\"||Rv|| =\", np.linalg.norm(v_rotated))\n",
    "print(\"Length preserved?\", np.isclose(np.linalg.norm(v), np.linalg.norm(v_rotated)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Visualize Rotation of Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define several vectors to rotate\n",
    "vectors = np.array([[2, 0],\n",
    "                    [1, 2],\n",
    "                    [0, 1.5],\n",
    "                    [-1, 1]])\n",
    "\n",
    "# Rotation angle: 45 degrees\n",
    "theta = np.pi / 4\n",
    "R = rotation_matrix_2d(theta)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#9b59b6']\n",
    "\n",
    "for i, v in enumerate(vectors):\n",
    "    v_rot = R @ v\n",
    "    \n",
    "    # Original vector (solid arrow)\n",
    "    ax.annotate('', xy=v, xytext=(0, 0),\n",
    "                arrowprops=dict(arrowstyle='->', color=colors[i], lw=2))\n",
    "    ax.text(v[0] + 0.05, v[1] + 0.1, f'$v_{i+1}$',\n",
    "            fontsize=12, color=colors[i])\n",
    "    \n",
    "    # Rotated vector (dashed arrow)\n",
    "    ax.annotate('', xy=v_rot, xytext=(0, 0),\n",
    "                arrowprops=dict(arrowstyle='->', color=colors[i],\n",
    "                                lw=2, linestyle='dashed'))\n",
    "    ax.text(v_rot[0] + 0.05, v_rot[1] + 0.1, f\"$v_{i+1}'$\",\n",
    "            fontsize=12, color=colors[i], style='italic')\n",
    "\n",
    "# Draw rotation arc for one vector\n",
    "arc_angles = np.linspace(0, theta, 30)\n",
    "arc_r = 0.8\n",
    "ax.plot(arc_r * np.cos(arc_angles), arc_r * np.sin(arc_angles),\n",
    "        'k-', lw=1.5)\n",
    "ax.text(0.85, 0.3, r'$\\theta = 45째$', fontsize=11)\n",
    "\n",
    "ax.set_xlim(-3, 3)\n",
    "ax.set_ylim(-1, 3.5)\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(0, color='k', linewidth=0.5)\n",
    "ax.axvline(0, color='k', linewidth=0.5)\n",
    "ax.set_title(f'2D Rotation by {np.degrees(theta):.0f} Degrees\\n'\n",
    "             f'(solid = original, dashed = rotated)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "In this notebook we covered the key concepts of **Analytic Geometry** for machine learning:\n",
    "\n",
    "| Topic | Key Idea |\n",
    "|-------|----------|\n",
    "| **Norms** | Measure vector length (L1, L2, L-inf) |\n",
    "| **Inner Products** | Generalized dot product; requires positive definite matrix |\n",
    "| **Distances & Angles** | Euclidean distance, cosine similarity, Cauchy-Schwarz |\n",
    "| **Orthogonality** | Vectors with zero inner product; orthogonal matrices |\n",
    "| **Projections** | Closest point in a subspace; $B(B^\\top B)^{-1}B^\\top$ |\n",
    "| **Gram-Schmidt** | Produces orthonormal basis from independent vectors |\n",
    "| **Rotations** | Length-preserving linear maps; orthogonal with det = 1 |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Exercises\n",
    "\n",
    "Try these on your own:\n",
    "\n",
    "---\n",
    "\n",
    "**Exercise 1: Norms and Unit Vectors**\n",
    "\n",
    "Given the vector $\\mathbf{v} = (3, -1, 2, -4, 5)$:\n",
    "1. Compute the L1, L2, and L-infinity norms.\n",
    "2. Normalize $\\mathbf{v}$ to have unit L2 norm and verify that $\\|\\hat{\\mathbf{v}}\\|_2 = 1$.\n",
    "3. For which $p$-norm is the norm of $\\mathbf{v}$ the largest? The smallest?\n",
    "\n",
    "---\n",
    "\n",
    "**Exercise 2: Inner Products and Angles**\n",
    "\n",
    "Let $\\mathbf{a} = (1, 2, 3)$ and $\\mathbf{b} = (4, -5, 6)$.\n",
    "1. Compute the standard dot product $\\langle \\mathbf{a}, \\mathbf{b} \\rangle$.\n",
    "2. Find the angle between $\\mathbf{a}$ and $\\mathbf{b}$ in degrees.\n",
    "3. Define the matrix $A = \\begin{pmatrix} 2 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 3 \\end{pmatrix}$ and compute the generalized inner product $\\mathbf{a}^\\top A \\mathbf{b}$. Is this matrix positive definite?\n",
    "\n",
    "---\n",
    "\n",
    "**Exercise 3: Projections**\n",
    "\n",
    "Consider the vector $\\mathbf{x} = (1, 2, 3)$ and the subspace spanned by $\\mathbf{b}_1 = (1, 1, 0)$ and $\\mathbf{b}_2 = (0, 1, 1)$.\n",
    "1. Form the matrix $B = [\\mathbf{b}_1 \\,|\\, \\mathbf{b}_2]$ and compute the projection matrix $P = B(B^\\top B)^{-1}B^\\top$.\n",
    "2. Compute the projection $\\hat{\\mathbf{x}} = P\\mathbf{x}$.\n",
    "3. Verify that the residual $\\mathbf{x} - \\hat{\\mathbf{x}}$ is orthogonal to both $\\mathbf{b}_1$ and $\\mathbf{b}_2$.\n",
    "\n",
    "---\n",
    "\n",
    "**Exercise 4: Gram-Schmidt and Rotations**\n",
    "\n",
    "1. Apply the Gram-Schmidt process to the vectors $\\mathbf{v}_1 = (1, 1, 0)$, $\\mathbf{v}_2 = (1, 0, 1)$, $\\mathbf{v}_3 = (0, 1, 1)$ and verify that the result is an orthonormal set.\n",
    "2. Create a rotation matrix that rotates by $60째$ and apply it to the vector $(1, 0)$. Verify that the resulting vector has the same length as the original.\n",
    "3. Show that applying two successive rotations $R(\\alpha)$ and $R(\\beta)$ is the same as $R(\\alpha + \\beta)$. Test with $\\alpha = 30째$ and $\\beta = 45째$.\n",
    "\n",
    "---\n",
    "\n",
    "**Course:** Mathematics for Machine Learning  \n",
    "**Instructor:** Mohammed Alnemari"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}