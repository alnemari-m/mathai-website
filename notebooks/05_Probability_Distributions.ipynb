{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability and Distributions\n",
    "\n",
    "**Course:** Mathematics for Machine Learning  \n",
    "**Instructor:** Mohammed Alnemari\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "This notebook covers probability distributions and related concepts essential for machine learning:\n",
    "\n",
    "1. **Discrete Distributions** - Bernoulli, Binomial, Geometric\n",
    "2. **Continuous Distributions** - Uniform, Exponential, Gaussian\n",
    "3. **Bayes' Theorem** - Prior, likelihood, and posterior\n",
    "4. **Joint and Marginal Distributions** - 2D distributions and marginalization\n",
    "5. **Covariance and Correlation** - Measuring linear relationships\n",
    "6. **Gaussian Distribution** - Univariate and multivariate\n",
    "7. **Central Limit Theorem** - Why the Gaussian is everywhere\n",
    "\n",
    "---\n",
    "\n",
    "## Google Colab Ready!\n",
    "\n",
    "This notebook works perfectly in Google Colab. All required libraries are pre-installed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Plotting settings\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Discrete Distributions\n",
    "\n",
    "Discrete random variables take on countable values. We study three foundational discrete distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Bernoulli Distribution\n",
    "\n",
    "A single trial with two outcomes: success (1) with probability $p$, or failure (0) with probability $1 - p$.\n",
    "\n",
    "$$P(X = k) = p^k (1 - p)^{1-k}, \\quad k \\in \\{0, 1\\}$$\n",
    "\n",
    "- Mean: $\\mu = p$\n",
    "- Variance: $\\sigma^2 = p(1-p)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli Distribution\n",
    "p = 0.7\n",
    "bernoulli = stats.bernoulli(p)\n",
    "\n",
    "# PMF values\n",
    "k_values = [0, 1]\n",
    "pmf_values = bernoulli.pmf(k_values)\n",
    "\n",
    "print(f\"Bernoulli(p={p})\")\n",
    "print(f\"P(X=0) = {pmf_values[0]:.4f}\")\n",
    "print(f\"P(X=1) = {pmf_values[1]:.4f}\")\n",
    "print()\n",
    "\n",
    "# Verify mean and variance against formulas\n",
    "print(f\"Mean (scipy):   {bernoulli.mean():.4f}\")\n",
    "print(f\"Mean (formula): {p:.4f}\")\n",
    "print(f\"Variance (scipy):   {bernoulli.var():.4f}\")\n",
    "print(f\"Variance (formula): {p * (1 - p):.4f}\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.bar(k_values, pmf_values, color=['#e74c3c', '#2ecc71'], edgecolor='black', width=0.4)\n",
    "ax.set_xticks(k_values)\n",
    "ax.set_xticklabels(['Failure (0)', 'Success (1)'])\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_title(f'Bernoulli Distribution (p = {p})')\n",
    "ax.set_ylim(0, 1)\n",
    "for i, v in enumerate(pmf_values):\n",
    "    ax.text(i, v + 0.02, f'{v:.2f}', ha='center', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Binomial Distribution\n",
    "\n",
    "The number of successes in $n$ independent Bernoulli trials, each with success probability $p$.\n",
    "\n",
    "$$P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}, \\quad k = 0, 1, \\dots, n$$\n",
    "\n",
    "- Mean: $\\mu = np$\n",
    "- Variance: $\\sigma^2 = np(1-p)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binomial Distribution for different parameters\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "params = [(10, 0.5), (20, 0.3), (20, 0.7)]\n",
    "\n",
    "for ax, (n, p) in zip(axes, params):\n",
    "    binom = stats.binom(n, p)\n",
    "    k = np.arange(0, n + 1)\n",
    "    pmf = binom.pmf(k)\n",
    "\n",
    "    ax.bar(k, pmf, color='steelblue', edgecolor='black', alpha=0.8)\n",
    "    ax.set_xlabel('k')\n",
    "    ax.set_ylabel('P(X = k)')\n",
    "    ax.set_title(f'Binomial(n={n}, p={p})')\n",
    "\n",
    "    # Verify mean and variance\n",
    "    print(f\"Binomial(n={n}, p={p}):\")\n",
    "    print(f\"  Mean  -> scipy: {binom.mean():.4f}, formula (np): {n * p:.4f}\")\n",
    "    print(f\"  Var   -> scipy: {binom.var():.4f}, formula (np(1-p)): {n * p * (1 - p):.4f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Geometric Distribution\n",
    "\n",
    "The number of trials needed to get the first success.\n",
    "\n",
    "$$P(X = k) = (1-p)^{k-1} p, \\quad k = 1, 2, 3, \\dots$$\n",
    "\n",
    "- Mean: $\\mu = 1/p$\n",
    "- Variance: $\\sigma^2 = (1-p)/p^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometric Distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
    "p_values = [0.2, 0.5, 0.8]\n",
    "\n",
    "for p, color in zip(p_values, colors):\n",
    "    geom = stats.geom(p)\n",
    "    k = np.arange(1, 16)\n",
    "    pmf = geom.pmf(k)\n",
    "\n",
    "    ax.plot(k, pmf, 'o-', color=color, label=f'p = {p}', markersize=6)\n",
    "\n",
    "    # Verify mean and variance\n",
    "    print(f\"Geometric(p={p}):\")\n",
    "    print(f\"  Mean  -> scipy: {geom.mean():.4f}, formula (1/p): {1 / p:.4f}\")\n",
    "    print(f\"  Var   -> scipy: {geom.var():.4f}, formula ((1-p)/p^2): {(1 - p) / p**2:.4f}\")\n",
    "\n",
    "ax.set_xlabel('k (number of trials)')\n",
    "ax.set_ylabel('P(X = k)')\n",
    "ax.set_title('Geometric Distribution PMF')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Continuous Distributions\n",
    "\n",
    "Continuous random variables can take any value in an interval. We describe them using probability density functions (PDFs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Uniform Distribution\n",
    "\n",
    "Every value in the interval $[a, b]$ is equally likely.\n",
    "\n",
    "$$f(x) = \\frac{1}{b - a}, \\quad a \\le x \\le b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform Distribution\n",
    "a, b = 2, 8\n",
    "uniform = stats.uniform(loc=a, scale=b - a)  # scipy parameterizes as (loc, scale)\n",
    "\n",
    "x = np.linspace(0, 10, 500)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# PDF\n",
    "axes[0].plot(x, uniform.pdf(x), 'b-', linewidth=2)\n",
    "axes[0].fill_between(x, uniform.pdf(x), alpha=0.3)\n",
    "axes[0].set_title(f'Uniform PDF on [{a}, {b}]')\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('f(x)')\n",
    "axes[0].set_ylim(0, 0.25)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# CDF\n",
    "axes[1].plot(x, uniform.cdf(x), 'r-', linewidth=2)\n",
    "axes[1].set_title(f'Uniform CDF on [{a}, {b}]')\n",
    "axes[1].set_xlabel('x')\n",
    "axes[1].set_ylabel('F(x)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sample and compare with theoretical PDF\n",
    "samples = uniform.rvs(size=5000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(samples, bins=40, density=True, alpha=0.6, color='steelblue', edgecolor='black', label='Histogram of samples')\n",
    "ax.plot(x, uniform.pdf(x), 'r-', linewidth=2, label='Theoretical PDF')\n",
    "ax.set_title('Uniform Distribution: Samples vs Theoretical PDF')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean  -> scipy: {uniform.mean():.4f}, formula ((a+b)/2): {(a + b) / 2:.4f}\")\n",
    "print(f\"Var   -> scipy: {uniform.var():.4f}, formula ((b-a)^2/12): {(b - a)**2 / 12:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Exponential Distribution\n",
    "\n",
    "Models the time between events in a Poisson process.\n",
    "\n",
    "$$f(x) = \\lambda e^{-\\lambda x}, \\quad x \\ge 0$$\n",
    "\n",
    "- Mean: $\\mu = 1/\\lambda$\n",
    "- Variance: $\\sigma^2 = 1/\\lambda^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential Distribution\n",
    "x = np.linspace(0, 8, 500)\n",
    "lambdas = [0.5, 1.0, 2.0]\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for lam, color in zip(lambdas, colors):\n",
    "    exp_dist = stats.expon(scale=1 / lam)  # scipy uses scale = 1/lambda\n",
    "    axes[0].plot(x, exp_dist.pdf(x), color=color, linewidth=2, label=f'$\\\\lambda$ = {lam}')\n",
    "    axes[1].plot(x, exp_dist.cdf(x), color=color, linewidth=2, label=f'$\\\\lambda$ = {lam}')\n",
    "\n",
    "axes[0].set_title('Exponential PDF')\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('f(x)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_title('Exponential CDF')\n",
    "axes[1].set_xlabel('x')\n",
    "axes[1].set_ylabel('F(x)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sample and compare\n",
    "lam = 1.5\n",
    "exp_dist = stats.expon(scale=1 / lam)\n",
    "samples = exp_dist.rvs(size=5000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(samples, bins=50, density=True, alpha=0.6, color='steelblue', edgecolor='black', label='Histogram of samples')\n",
    "ax.plot(x, exp_dist.pdf(x), 'r-', linewidth=2, label=f'Theoretical PDF ($\\\\lambda$ = {lam})')\n",
    "ax.set_title('Exponential Distribution: Samples vs Theoretical PDF')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean  -> scipy: {exp_dist.mean():.4f}, formula (1/lambda): {1 / lam:.4f}\")\n",
    "print(f\"Var   -> scipy: {exp_dist.var():.4f}, formula (1/lambda^2): {1 / lam**2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Gaussian (Normal) Distribution\n",
    "\n",
    "The most important distribution in statistics and machine learning.\n",
    "\n",
    "$$f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Distribution\n",
    "x = np.linspace(-8, 12, 500)\n",
    "\n",
    "gaussians = [\n",
    "    (0, 1, 'Standard Normal'),\n",
    "    (2, 0.5, '$\\\\mu=2, \\\\sigma=0.5$'),\n",
    "    (-1, 2, '$\\\\mu=-1, \\\\sigma=2$'),\n",
    "]\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for (mu, sigma, label), color in zip(gaussians, colors):\n",
    "    norm_dist = stats.norm(loc=mu, scale=sigma)\n",
    "    axes[0].plot(x, norm_dist.pdf(x), color=color, linewidth=2, label=label)\n",
    "    axes[1].plot(x, norm_dist.cdf(x), color=color, linewidth=2, label=label)\n",
    "\n",
    "axes[0].set_title('Gaussian PDF')\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('f(x)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_title('Gaussian CDF')\n",
    "axes[1].set_xlabel('x')\n",
    "axes[1].set_ylabel('F(x)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sample and compare\n",
    "mu, sigma = 3, 1.5\n",
    "norm_dist = stats.norm(loc=mu, scale=sigma)\n",
    "samples = norm_dist.rvs(size=5000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(samples, bins=50, density=True, alpha=0.6, color='steelblue', edgecolor='black', label='Histogram of samples')\n",
    "x_plot = np.linspace(mu - 4 * sigma, mu + 4 * sigma, 500)\n",
    "ax.plot(x_plot, norm_dist.pdf(x_plot), 'r-', linewidth=2, label=f'Theoretical PDF ($\\\\mu$={mu}, $\\\\sigma$={sigma})')\n",
    "ax.set_title('Gaussian Distribution: Samples vs Theoretical PDF')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Bayes' Theorem\n",
    "\n",
    "Bayes' theorem lets us update our beliefs given new evidence:\n",
    "\n",
    "$$P(A \\mid B) = \\frac{P(B \\mid A) \\, P(A)}{P(B)}$$\n",
    "\n",
    "We illustrate this with a classic **medical test** example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Medical Test Example\n",
    "\n",
    "Suppose:\n",
    "- **Prevalence** (prior probability of disease): $P(D) = 0.01$ (1% of the population has the disease)\n",
    "- **Sensitivity** (true positive rate): $P(+|D) = 0.95$ (test correctly detects 95% of sick people)\n",
    "- **Specificity** (true negative rate): $P(-|\\neg D) = 0.90$ (test correctly identifies 90% of healthy people)\n",
    "\n",
    "**Question:** If a person tests positive, what is the probability they actually have the disease?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes' Theorem - Medical Test Example\n",
    "\n",
    "# Given probabilities\n",
    "P_disease = 0.01           # Prevalence (prior)\n",
    "P_no_disease = 1 - P_disease\n",
    "P_pos_given_disease = 0.95  # Sensitivity\n",
    "P_neg_given_no_disease = 0.90  # Specificity\n",
    "P_pos_given_no_disease = 1 - P_neg_given_no_disease  # False positive rate\n",
    "\n",
    "# Total probability of testing positive (Law of Total Probability)\n",
    "P_pos = P_pos_given_disease * P_disease + P_pos_given_no_disease * P_no_disease\n",
    "\n",
    "# Bayes' Theorem: P(Disease | Positive)\n",
    "P_disease_given_pos = (P_pos_given_disease * P_disease) / P_pos\n",
    "\n",
    "print(\"=== Medical Test - Bayes' Theorem ===\")\n",
    "print(f\"Prior P(Disease)          = {P_disease:.4f}\")\n",
    "print(f\"Sensitivity P(+|D)        = {P_pos_given_disease:.4f}\")\n",
    "print(f\"Specificity P(-|~D)       = {P_neg_given_no_disease:.4f}\")\n",
    "print(f\"False positive rate P(+|~D) = {P_pos_given_no_disease:.4f}\")\n",
    "print(f\"P(+)                      = {P_pos:.4f}\")\n",
    "print()\n",
    "print(f\"Posterior P(Disease|+)    = {P_disease_given_pos:.4f}\")\n",
    "print()\n",
    "print(f\"Despite a positive test, there is only a {P_disease_given_pos:.1%} chance\")\n",
    "print(f\"that the patient actually has the disease!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Visualizing Prior vs Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prior vs posterior\n",
    "categories = ['Has Disease', 'No Disease']\n",
    "prior = [P_disease, P_no_disease]\n",
    "posterior = [P_disease_given_pos, 1 - P_disease_given_pos]\n",
    "\n",
    "x_pos = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars1 = ax.bar(x_pos - width / 2, prior, width, label='Prior P(D)', color='#3498db', edgecolor='black')\n",
    "bars2 = ax.bar(x_pos + width / 2, posterior, width, label='Posterior P(D|+)', color='#e74c3c', edgecolor='black')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_title('Prior vs Posterior Probability after Positive Test')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    h = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, h + 0.01, f'{h:.4f}', ha='center', fontsize=10)\n",
    "for bar in bars2:\n",
    "    h = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, h + 0.01, f'{h:.4f}', ha='center', fontsize=10)\n",
    "\n",
    "ax.set_ylim(0, 1.15)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How posterior changes with prevalence\n",
    "prevalences = np.linspace(0.001, 0.5, 200)\n",
    "posteriors = (P_pos_given_disease * prevalences) / (\n",
    "    P_pos_given_disease * prevalences + P_pos_given_no_disease * (1 - prevalences)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(prevalences, posteriors, 'b-', linewidth=2)\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='P = 0.5')\n",
    "ax.axvline(x=0.01, color='red', linestyle='--', alpha=0.5, label=f'Prevalence = 0.01')\n",
    "ax.plot(0.01, P_disease_given_pos, 'ro', markersize=10, zorder=5)\n",
    "ax.annotate(f'  ({0.01}, {P_disease_given_pos:.3f})', xy=(0.01, P_disease_given_pos),\n",
    "            fontsize=11, color='red')\n",
    "ax.set_xlabel('Prevalence P(Disease)')\n",
    "ax.set_ylabel('Posterior P(Disease | Positive Test)')\n",
    "ax.set_title('Effect of Disease Prevalence on Posterior Probability')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Joint and Marginal Distributions\n",
    "\n",
    "A **joint distribution** $P(X, Y)$ describes the probability of two random variables simultaneously.\n",
    "\n",
    "**Marginal distributions** are obtained by summing (discrete) or integrating (continuous) over the other variable:\n",
    "\n",
    "$$P(X = x) = \\sum_y P(X = x, Y = y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Creating a Joint Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a discrete joint distribution table\n",
    "# Example: X = Weather {Sunny=0, Cloudy=1, Rainy=2}\n",
    "#          Y = Mood    {Happy=0, Neutral=1, Sad=2}\n",
    "\n",
    "# Joint probability table P(X, Y)\n",
    "joint = np.array([\n",
    "    [0.20, 0.10, 0.02],  # Sunny\n",
    "    [0.08, 0.15, 0.07],  # Cloudy\n",
    "    [0.02, 0.10, 0.26],  # Rainy\n",
    "])\n",
    "\n",
    "x_labels = ['Sunny', 'Cloudy', 'Rainy']\n",
    "y_labels = ['Happy', 'Neutral', 'Sad']\n",
    "\n",
    "print(\"Joint Distribution P(X, Y):\")\n",
    "print(f\"{'':>10}\", end='')\n",
    "for yl in y_labels:\n",
    "    print(f\"{yl:>10}\", end='')\n",
    "print()\n",
    "for i, xl in enumerate(x_labels):\n",
    "    print(f\"{xl:>10}\", end='')\n",
    "    for j in range(len(y_labels)):\n",
    "        print(f\"{joint[i, j]:>10.2f}\", end='')\n",
    "    print()\n",
    "\n",
    "print(f\"\\nTotal probability: {joint.sum():.2f} (should be 1.00)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Computing Marginal Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marginal distributions by summing over the other variable\n",
    "P_X = joint.sum(axis=1)  # Sum over Y (columns) -> P(X)\n",
    "P_Y = joint.sum(axis=0)  # Sum over X (rows) -> P(Y)\n",
    "\n",
    "print(\"Marginal P(X) [Weather]:\")\n",
    "for label, prob in zip(x_labels, P_X):\n",
    "    print(f\"  P({label}) = {prob:.2f}\")\n",
    "print()\n",
    "\n",
    "print(\"Marginal P(Y) [Mood]:\")\n",
    "for label, prob in zip(y_labels, P_Y):\n",
    "    print(f\"  P({label}) = {prob:.2f}\")\n",
    "\n",
    "# Verify marginals sum to 1\n",
    "print(f\"\\nSum of P(X): {P_X.sum():.2f}\")\n",
    "print(f\"Sum of P(Y): {P_Y.sum():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Visualizing the Joint Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Heatmap of joint distribution\n",
    "im = axes[0].imshow(joint, cmap='Blues', aspect='auto')\n",
    "axes[0].set_xticks(range(len(y_labels)))\n",
    "axes[0].set_xticklabels(y_labels)\n",
    "axes[0].set_yticks(range(len(x_labels)))\n",
    "axes[0].set_yticklabels(x_labels)\n",
    "axes[0].set_title('Joint Distribution P(X, Y)')\n",
    "axes[0].set_xlabel('Mood (Y)')\n",
    "axes[0].set_ylabel('Weather (X)')\n",
    "# Annotate cells\n",
    "for i in range(len(x_labels)):\n",
    "    for j in range(len(y_labels)):\n",
    "        axes[0].text(j, i, f'{joint[i, j]:.2f}', ha='center', va='center',\n",
    "                     fontsize=14, fontweight='bold',\n",
    "                     color='white' if joint[i, j] > 0.15 else 'black')\n",
    "plt.colorbar(im, ax=axes[0], shrink=0.8)\n",
    "\n",
    "# Marginal P(X)\n",
    "axes[1].bar(x_labels, P_X, color='#3498db', edgecolor='black')\n",
    "axes[1].set_title('Marginal P(X) [Weather]')\n",
    "axes[1].set_ylabel('Probability')\n",
    "for i, v in enumerate(P_X):\n",
    "    axes[1].text(i, v + 0.01, f'{v:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Marginal P(Y)\n",
    "axes[2].bar(y_labels, P_Y, color='#e74c3c', edgecolor='black')\n",
    "axes[2].set_title('Marginal P(Y) [Mood]')\n",
    "axes[2].set_ylabel('Probability')\n",
    "for i, v in enumerate(P_Y):\n",
    "    axes[2].text(i, v + 0.01, f'{v:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Covariance and Correlation\n",
    "\n",
    "**Covariance** measures how two variables change together:\n",
    "\n",
    "$$\\text{Cov}(X, Y) = E[(X - \\mu_X)(Y - \\mu_Y)]$$\n",
    "\n",
    "**Correlation** is the normalized covariance:\n",
    "\n",
    "$$\\rho_{XY} = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y}, \\quad -1 \\le \\rho \\le 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Generating Correlated Random Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate correlated random variables using Cholesky decomposition\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Define the desired covariance matrix\n",
    "mean = [0, 0]\n",
    "cov_matrix = [[1.0, 0.8],\n",
    "              [0.8, 1.0]]\n",
    "\n",
    "# Generate samples from multivariate normal\n",
    "samples = np.random.multivariate_normal(mean, cov_matrix, n_samples)\n",
    "X = samples[:, 0]\n",
    "Y = samples[:, 1]\n",
    "\n",
    "print(\"Desired covariance matrix:\")\n",
    "print(np.array(cov_matrix))\n",
    "print()\n",
    "\n",
    "# Compute sample covariance matrix\n",
    "sample_cov = np.cov(X, Y)\n",
    "print(\"Sample covariance matrix (np.cov):\")\n",
    "print(sample_cov)\n",
    "print()\n",
    "\n",
    "# Compute sample correlation matrix\n",
    "sample_corr = np.corrcoef(X, Y)\n",
    "print(\"Sample correlation matrix (np.corrcoef):\")\n",
    "print(sample_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Manual Computation of Covariance and Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual computation\n",
    "cov_manual = np.mean((X - np.mean(X)) * (Y - np.mean(Y)))\n",
    "corr_manual = cov_manual / (np.std(X) * np.std(Y))\n",
    "\n",
    "print(f\"Manual Cov(X, Y):  {cov_manual:.4f}\")\n",
    "print(f\"np.cov result:     {sample_cov[0, 1]:.4f}  (uses N-1 denominator)\")\n",
    "print()\n",
    "print(f\"Manual Corr(X, Y): {corr_manual:.4f}\")\n",
    "print(f\"np.corrcoef result: {sample_corr[0, 1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Visualizing Different Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots for different correlation values\n",
    "np.random.seed(42)\n",
    "correlations = [-0.9, -0.5, 0.0, 0.5, 0.9]\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "for ax, rho in zip(axes, correlations):\n",
    "    cov_mat = [[1.0, rho],\n",
    "               [rho, 1.0]]\n",
    "    data = np.random.multivariate_normal([0, 0], cov_mat, 500)\n",
    "\n",
    "    ax.scatter(data[:, 0], data[:, 1], alpha=0.4, s=10, color='steelblue')\n",
    "    ax.set_title(f'$\\\\rho$ = {rho}')\n",
    "    ax.set_xlim(-4, 4)\n",
    "    ax.set_ylim(-4, 4)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlabel('X')\n",
    "    if rho == correlations[0]:\n",
    "        ax.set_ylabel('Y')\n",
    "\n",
    "plt.suptitle('Scatter Plots for Different Correlation Values', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: Gaussian Distribution (Deep Dive)\n",
    "\n",
    "The Gaussian distribution is central to machine learning. We explore both the univariate and multivariate cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Univariate Gaussian\n",
    "\n",
    "$$\\mathcal{N}(x \\mid \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Gaussian for different parameters\n",
    "x = np.linspace(-8, 12, 500)\n",
    "\n",
    "params = [\n",
    "    (0, 1, 'steelblue'),\n",
    "    (0, 2, '#e74c3c'),\n",
    "    (0, 0.5, '#2ecc71'),\n",
    "    (3, 1, '#9b59b6'),\n",
    "    (-2, 1.5, '#f39c12'),\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for mu, sigma, color in params:\n",
    "    pdf = stats.norm.pdf(x, loc=mu, scale=sigma)\n",
    "    ax.plot(x, pdf, color=color, linewidth=2,\n",
    "            label=f'$\\\\mu={mu}, \\\\sigma={sigma}$')\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('f(x)')\n",
    "ax.set_title('Univariate Gaussian for Different Parameters')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Multivariate Gaussian\n",
    "\n",
    "For a $d$-dimensional random vector $\\mathbf{x}$:\n",
    "\n",
    "$$\\mathcal{N}(\\mathbf{x} \\mid \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}) = \\frac{1}{(2\\pi)^{d/2} |\\boldsymbol{\\Sigma}|^{1/2}} \\exp\\left(-\\frac{1}{2}(\\mathbf{x} - \\boldsymbol{\\mu})^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu})\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Multivariate Gaussian contour plots\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Define grid\n",
    "x_grid = np.linspace(-4, 4, 200)\n",
    "y_grid = np.linspace(-4, 4, 200)\n",
    "X_grid, Y_grid = np.meshgrid(x_grid, y_grid)\n",
    "pos = np.dstack((X_grid, Y_grid))\n",
    "\n",
    "# Different covariance matrices\n",
    "configs = [\n",
    "    ([0, 0], [[1, 0], [0, 1]], 'Isotropic ($\\\\Sigma = I$)'),\n",
    "    ([0, 0], [[2, 0], [0, 0.5]], 'Axis-aligned'),\n",
    "    ([0, 0], [[1, 0.8], [0.8, 1]], 'Correlated ($\\\\rho = 0.8$)'),\n",
    "]\n",
    "\n",
    "for ax, (mean, cov, title) in zip(axes, configs):\n",
    "    rv = multivariate_normal(mean, cov)\n",
    "    Z = rv.pdf(pos)\n",
    "\n",
    "    contour = ax.contourf(X_grid, Y_grid, Z, levels=20, cmap='Blues')\n",
    "    ax.contour(X_grid, Y_grid, Z, levels=6, colors='navy', linewidths=0.5, alpha=0.5)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('$x_1$')\n",
    "    ax.set_ylabel('$x_2$')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    plt.colorbar(contour, ax=ax, shrink=0.8)\n",
    "\n",
    "plt.suptitle('2D Multivariate Gaussian Distributions', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Sampling from Multivariate Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from multivariate Gaussian and visualize\n",
    "np.random.seed(42)\n",
    "\n",
    "mean = [1, -1]\n",
    "cov = [[2.0, 1.2],\n",
    "       [1.2, 1.0]]\n",
    "\n",
    "samples = np.random.multivariate_normal(mean, cov, 2000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Scatter plot of samples\n",
    "ax.scatter(samples[:, 0], samples[:, 1], alpha=0.3, s=8, color='steelblue', label='Samples')\n",
    "\n",
    "# Overlay theoretical contours\n",
    "x_grid = np.linspace(-5, 7, 200)\n",
    "y_grid = np.linspace(-5, 3, 200)\n",
    "X_grid, Y_grid = np.meshgrid(x_grid, y_grid)\n",
    "pos = np.dstack((X_grid, Y_grid))\n",
    "rv = multivariate_normal(mean, cov)\n",
    "Z = rv.pdf(pos)\n",
    "\n",
    "ax.contour(X_grid, Y_grid, Z, levels=8, colors='red', linewidths=1.5, alpha=0.8)\n",
    "ax.plot(mean[0], mean[1], 'r*', markersize=15, label=f'Mean ({mean[0]}, {mean[1]})')\n",
    "\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.set_title('Samples from 2D Gaussian with Theoretical Contours')\n",
    "ax.legend()\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Verify sample statistics\n",
    "print(\"True mean:\", mean)\n",
    "print(\"Sample mean:\", np.mean(samples, axis=0).round(3))\n",
    "print()\n",
    "print(\"True covariance:\")\n",
    "print(np.array(cov))\n",
    "print(\"Sample covariance:\")\n",
    "print(np.cov(samples.T).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 7: Central Limit Theorem\n",
    "\n",
    "The **Central Limit Theorem (CLT)** states that the sum (or average) of a large number of independent, identically distributed random variables will be approximately normally distributed, regardless of the original distribution.\n",
    "\n",
    "If $X_1, X_2, \\dots, X_n$ are i.i.d. with mean $\\mu$ and variance $\\sigma^2$, then as $n \\to \\infty$:\n",
    "\n",
    "$$\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i \\xrightarrow{d} \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 CLT Demonstration: Sum of Uniform Random Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central Limit Theorem demonstration\n",
    "# Sum of Uniform(0,1) random variables -> approaches Gaussian\n",
    "\n",
    "np.random.seed(42)\n",
    "n_experiments = 10000\n",
    "n_values = [1, 2, 5, 10, 30, 100]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Uniform(0,1) has mean=0.5, var=1/12\n",
    "mu_uniform = 0.5\n",
    "var_uniform = 1 / 12\n",
    "\n",
    "for ax, n in zip(axes, n_values):\n",
    "    # Generate n_experiments sums, each summing n uniform random variables\n",
    "    sums = np.sum(np.random.uniform(0, 1, (n_experiments, n)), axis=1)\n",
    "\n",
    "    # Standardize: Z = (S_n - n*mu) / sqrt(n*var)\n",
    "    standardized = (sums - n * mu_uniform) / np.sqrt(n * var_uniform)\n",
    "\n",
    "    # Plot histogram\n",
    "    ax.hist(standardized, bins=50, density=True, alpha=0.6,\n",
    "            color='steelblue', edgecolor='black', label='Empirical')\n",
    "\n",
    "    # Overlay standard normal\n",
    "    x = np.linspace(-4, 4, 200)\n",
    "    ax.plot(x, stats.norm.pdf(x), 'r-', linewidth=2, label='N(0, 1)')\n",
    "\n",
    "    ax.set_title(f'n = {n}', fontsize=13)\n",
    "    ax.set_xlim(-4, 4)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Central Limit Theorem: Sum of Uniform(0,1) Variables (Standardized)',\n",
    "             fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 CLT Convergence: Tracking the Distribution Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure how quickly the CLT converges\n",
    "# Use Kolmogorov-Smirnov test to compare sample means with normal distribution\n",
    "\n",
    "np.random.seed(42)\n",
    "n_values_fine = np.arange(1, 101)\n",
    "n_experiments = 5000\n",
    "ks_statistics = []\n",
    "\n",
    "for n in n_values_fine:\n",
    "    # Compute sample means of n uniform(0,1) draws\n",
    "    sample_means = np.mean(np.random.uniform(0, 1, (n_experiments, n)), axis=1)\n",
    "\n",
    "    # Standardize\n",
    "    standardized = (sample_means - mu_uniform) / np.sqrt(var_uniform / n)\n",
    "\n",
    "    # KS test against standard normal\n",
    "    ks_stat, _ = stats.kstest(standardized, 'norm')\n",
    "    ks_statistics.append(ks_stat)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(n_values_fine, ks_statistics, 'b-', linewidth=1.5)\n",
    "ax.axhline(y=0.05, color='red', linestyle='--', alpha=0.7, label='KS = 0.05 threshold')\n",
    "ax.set_xlabel('n (number of variables summed)')\n",
    "ax.set_ylabel('KS Statistic (distance from Normal)')\n",
    "ax.set_title('CLT Convergence: KS Statistic vs Sample Size')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find when KS statistic drops below 0.05\n",
    "ks_arr = np.array(ks_statistics)\n",
    "below_threshold = np.where(ks_arr < 0.05)[0]\n",
    "if len(below_threshold) > 0:\n",
    "    print(f\"KS statistic first drops below 0.05 at n = {below_threshold[0] + 1}\")\n",
    "else:\n",
    "    print(\"KS statistic did not drop below 0.05 in the tested range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 CLT with Non-Uniform Distributions\n",
    "\n",
    "The CLT works for any distribution with finite mean and variance. Let us verify with the exponential distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLT with Exponential distribution (highly skewed)\n",
    "np.random.seed(42)\n",
    "lam = 2.0  # rate parameter\n",
    "mu_exp = 1 / lam\n",
    "var_exp = 1 / lam**2\n",
    "\n",
    "n_experiments = 10000\n",
    "n_values = [1, 2, 5, 10, 30, 100]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for ax, n in zip(axes, n_values):\n",
    "    # Sample means from exponential\n",
    "    sample_means = np.mean(np.random.exponential(scale=1/lam, size=(n_experiments, n)), axis=1)\n",
    "\n",
    "    # Standardize\n",
    "    standardized = (sample_means - mu_exp) / np.sqrt(var_exp / n)\n",
    "\n",
    "    ax.hist(standardized, bins=50, density=True, alpha=0.6,\n",
    "            color='#2ecc71', edgecolor='black', label='Empirical')\n",
    "\n",
    "    x = np.linspace(-4, 4, 200)\n",
    "    ax.plot(x, stats.norm.pdf(x), 'r-', linewidth=2, label='N(0, 1)')\n",
    "\n",
    "    ax.set_title(f'n = {n}', fontsize=13)\n",
    "    ax.set_xlim(-4, 4)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('CLT with Exponential Distribution (Standardized Sample Means)',\n",
    "             fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Practice Exercises\n",
    "\n",
    "Try these on your own:\n",
    "\n",
    "1. **Poisson Distribution:** The Poisson distribution models the number of events in a fixed interval. Using `scipy.stats.poisson`, plot the PMF for $\\lambda = 1, 5, 10$. Verify that the mean and variance are both equal to $\\lambda$. Then draw 10,000 samples for $\\lambda = 5$ and overlay the histogram with the theoretical PMF.\n",
    "\n",
    "2. **Bayesian Coin Flip:** You have a coin that may be biased. Your prior belief is that $p$ (probability of heads) follows a Beta(2, 2) distribution. You flip the coin 10 times and observe 7 heads. Using Bayes' theorem, the posterior is Beta(2+7, 2+3) = Beta(9, 5). Plot the prior and posterior distributions on the same axes. Compute the prior and posterior means and print them.\n",
    "\n",
    "3. **Independence Test:** Generate two independent standard normal random variables $X$ and $Y$ (1000 samples each). Then create $Z = 2X + 3Y + \\text{noise}$. Compute the correlation matrix of $(X, Y, Z)$ using `np.corrcoef`. Which pairs are correlated and which are approximately independent? Visualize with a heatmap.\n",
    "\n",
    "4. **CLT with Dice:** Simulate rolling a fair six-sided die. The mean of a single die roll is $3.5$ and the variance is $35/12$. For $n \\in \\{1, 2, 5, 10, 50, 200\\}$, compute the average of $n$ dice rolls (repeat 10,000 times). Plot histograms of the standardized averages and overlay the standard normal PDF. At what $n$ does the distribution look approximately Gaussian?\n",
    "\n",
    "---\n",
    "\n",
    "**Course:** Mathematics for Machine Learning  \n",
    "**Instructor:** Mohammed Alnemari"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}